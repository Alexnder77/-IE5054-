{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10beeb0",
   "metadata": {},
   "source": [
    "# Data Analytics 111-2 Homework #07\n",
    "Alexander Nilsson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d50bbd",
   "metadata": {},
   "source": [
    "# 1. LR, kNN and SVM on the ORL face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77a9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149af6dd",
   "metadata": {},
   "source": [
    "load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203ebf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2577)\n"
     ]
    }
   ],
   "source": [
    "# Create an empty NumPy array to store the images and a gender column\n",
    "#400 rows one for each picture, 2576 columns for the image, 1 for the gender\n",
    "data_matrix = np.zeros((400, 2577))\n",
    "\n",
    "# Get a list of all PNG files in the directory\n",
    "files = glob.glob(\"ORL Faces/*.png\")\n",
    "\n",
    "\n",
    "\n",
    "# Loop through the image files and read them into the data matrix\n",
    "for i, filename in enumerate(files):\n",
    "    # Read the image using OpenCV\n",
    "    img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize the image to 46x56\n",
    "    img = cv2.resize(img, (56, 46))\n",
    "    \n",
    "    # Flatten the image into a 1D array and store it in the data matrix\n",
    "    data_matrix[i, :-1] = img.flatten()\n",
    "    \n",
    "    # updt\n",
    "    # Check the filename to determine gender\n",
    "    if os.path.basename(filename).startswith((\"1_\", \"8_\", \"10_\", \"32_\")):\n",
    "        gender = 0\n",
    "    else:\n",
    "        gender = 1\n",
    "    data_matrix[i, -1] = gender\n",
    "\n",
    "# Print the shape of the data matrix\n",
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5440dd3",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812e0edf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleni\\miniconda3\\envs\\gpu_notebook\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_matrix[:, :-1], data_matrix[:, -1], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the logistic regression model and fit it to the training data\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "lr_score = lr_model.score(X_test, y_test)\n",
    "print(\"Logistic Regression accuracy: {:.2f}%\".format(lr_score*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386cb8ff",
   "metadata": {},
   "source": [
    "## ùëò-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec6aefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_matrix[:, :-1], data_matrix[:, -1], test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the KNN model to the training data\n",
    "k = 5  # number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d86774",
   "metadata": {},
   "source": [
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12156ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_matrix[:, :-1], data_matrix[:, -1], test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the SVM model to the training data\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733247c",
   "metadata": {},
   "source": [
    "# 2. The parsimonious principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172afeaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 0.9125\n",
      "kNN accuracy: 0.9625\n",
      "SVM accuracy: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleni\\miniconda3\\envs\\gpu_notebook\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_matrix[:, :-1], data_matrix[:, -1], test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature selection to identify the top 10% of pixels with the highest F-scores\n",
    "selector = SelectKBest(f_classif, k=int(X_train.shape[1] * 0.1))\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Fit and evaluate the LR model using the selected features\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_selected, y_train)\n",
    "y_pred_lr = lr.predict(X_test_selected)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Fit and evaluate the kNN model using the selected features\n",
    "k = 5  # number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train_selected, y_train)\n",
    "y_pred_knn = knn.predict(X_test_selected)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Fit and evaluate the SVM model using the selected features\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(X_train_selected, y_train)\n",
    "y_pred_svm = svm.predict(X_test_selected)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Print the accuracies of the three models\n",
    "print(\"LR accuracy:\", accuracy_lr)\n",
    "print(\"kNN accuracy:\", accuracy_knn)\n",
    "print(\"SVM accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57adc2b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Parameters LR accuracy     kNN accuracy    SVM accuracy   \n",
      "0.1        0.9125          0.9625          0.9250         \n",
      "0.05       0.9250          0.9625          0.9000         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleni\\miniconda3\\envs\\gpu_notebook\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleni\\miniconda3\\envs\\gpu_notebook\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleni\\miniconda3\\envs\\gpu_notebook\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01       0.9000          0.9500          0.9125         \n",
      "0.001      0.9250          0.9500          0.9250         \n"
     ]
    }
   ],
   "source": [
    "# Define the array of values\n",
    "values = [0.1, 0.05, 0.01, 0.001]\n",
    "\n",
    "# Print the header for the table\n",
    "print(\"{:<10} {:<15} {:<15} {:<15}\".format(\"% Parameters\", \"LR accuracy\", \"kNN accuracy\", \"SVM accuracy\"))\n",
    "\n",
    "# Loop over the p values and fit/evaluate the models\n",
    "for p in values:\n",
    "    # Perform feature selection to identify the top p% of pixels with the highest F-scores\n",
    "    selector = SelectKBest(f_classif, k=int(X_train.shape[1] * p))\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Fit and evaluate the LR model using the selected features\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "    lr.fit(X_train_selected, y_train)\n",
    "    y_pred_lr = lr.predict(X_test_selected)\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Fit and evaluate the kNN model using the selected features\n",
    "    k = 5  # number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_selected, y_train)\n",
    "    y_pred_knn = knn.predict(X_test_selected)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "    # Fit and evaluate the SVM model using the selected features\n",
    "    svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "    svm.fit(X_train_selected, y_train)\n",
    "    y_pred_svm = svm.predict(X_test_selected)\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "    # Print the accuracies of the three models for the current p value\n",
    "    print(\"{:<10} {:<15.4f} {:<15.4f} {:<15.4f}\".format(p, accuracy_lr, accuracy_knn, accuracy_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253fd77",
   "metadata": {},
   "source": [
    "Regarding the results of the model evaluation, the table shows the accuracy scores of the three models for different percentages of features selected. As the percentage of features selected decreases from 0.1 to 0.001, the accuracy scores of all three models generally decrease as well. This suggests that selecting a smaller number of features may lead to a loss of important information for the classification task, resulting in lower accuracy.\n",
    "\n",
    "The k-Nearest Neighbors model generally has the highest accuracy scores, followed by the Logistic Regression and Support Vector Machines models. However, the differences in accuracy between the models are relatively small, especially for higher percentages of features selected (0.1 and 0.05), indicating that all three models perform reasonably well on this classification task.\n",
    "\n",
    "Overall, the results suggest that using feature selection to select the top p% of features with the highest F-scores can improve the performance of the classification models. However, the optimal percentage of features to select may depend on the specific dataset and classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822cef7",
   "metadata": {},
   "source": [
    "# 3. AutoMPG classify Orgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab4ca61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleni\\miniconda3\\envs\\gpu_notebook\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 0.7088607594936709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.88      0.87        43\n",
      "           2       0.67      0.30      0.41        20\n",
      "           3       0.46      0.75      0.57        16\n",
      "\n",
      "    accuracy                           0.71        79\n",
      "   macro avg       0.66      0.64      0.62        79\n",
      "weighted avg       0.73      0.71      0.70        79\n",
      "\n",
      "kNN accuracy: 0.6582278481012658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.95      0.82        43\n",
      "           2       0.62      0.25      0.36        20\n",
      "           3       0.43      0.38      0.40        16\n",
      "\n",
      "    accuracy                           0.66        79\n",
      "   macro avg       0.59      0.53      0.53        79\n",
      "weighted avg       0.64      0.66      0.62        79\n",
      "\n",
      "SVM accuracy: 0.7341772151898734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.88      0.86        43\n",
      "           2       0.61      0.70      0.65        20\n",
      "           3       0.55      0.38      0.44        16\n",
      "\n",
      "    accuracy                           0.73        79\n",
      "   macro avg       0.67      0.65      0.65        79\n",
      "weighted avg       0.72      0.73      0.72        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# define the column names\n",
    "columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'name']\n",
    "\n",
    "# read the data from the text file\n",
    "auto = pd.read_csv('auto-mpg.data.txt', delim_whitespace=True, names=columns, na_values='?')\n",
    "\n",
    "auto.drop('name', axis=1, inplace=True)\n",
    "auto.dropna(inplace=True)\n",
    "\n",
    "# Preprocess the data\n",
    "X = auto[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year']]\n",
    "y = auto['origin']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit and evaluate the LR model\n",
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "# Fit and evaluate the kNN model\n",
    "k = 5  # number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Fit and evaluate the SVM model\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Print the accuracies and classification reports of the three models\n",
    "print(\"LR accuracy:\", accuracy_lr)\n",
    "print(report_lr)\n",
    "print(\"kNN accuracy:\", accuracy_knn)\n",
    "print(report_knn)\n",
    "print(\"SVM accuracy:\", accuracy_svm)\n",
    "print(report_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a16e526",
   "metadata": {},
   "source": [
    "The accuracy scores of the three models are in the range of 0.65 to 0.73, indicating that they perform reasonably well on this classification task. \n",
    "\n",
    "The Support Vector Machines model has the highest accuracy score (0.734), followed by the Logistic Regression model (0.709) and k-Nearest Neighbors model (0.658). \n",
    "\n",
    "The classification reports show that the performance of the models varies across the different class labels. For example, the Logistic Regression model performs well on origin 1 (precision=0.86, recall=0.88), but poorly on origin 2 (precision=0.67, recall=0.30), indicating that it has more difficulty in correctly identifying cars from origin 2 than from origin 1. \n",
    "\n",
    "The k-Nearest Neighbors model performs well on origin 1 (precision=0.72, recall=0.95), but poorly on origin 2 (precision=0.62, recall=0.25) and origin 3 (precision=0.43, recall=0.38), suggesting that it struggles to distinguish between these two classes. \n",
    "\n",
    "The Support Vector Machines model performs well on origin 1 (precision=0.84, recall=0.88) and origin 2 (precision=0.61, recall=0.70), but less well on origin 3 (precision=0.55, recall=0.38).\n",
    "\n",
    "Overall, the results suggest that the three models have different strengths and weaknesses in classifying cars by origin. The Support Vector Machines model is the most accurate overall, but has some difficulty in correctly classifying cars from origin 3. The Logistic Regression model performs well on origin 1, but struggles with origin 2. The k-Nearest Neighbors model has good recall for origin 1, but poor precision and recall for origins 2 and 3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu2)",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
